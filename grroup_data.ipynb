{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grroup data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKUi0NOpPJRS"
      },
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# This method gets data based on grouping and datatype.\n",
        "def get_data(clips, grouping=\"default\", dtype=\"clip\"):\n",
        "    \n",
        "    # Return values based on keyword arguments\n",
        "    if grouping == \"default\":\n",
        "        return get_data_default(clips,dtype)\n",
        "    #if grouping == \"patient\":\n",
        "    #    return get_data_patient(clips,dtype)\n",
        "    #if grouping == \"chest location\":\n",
        "    #    return get_data_location(clips,dtype)\n",
        "    if grouping == \"recording equipment\":\n",
        "        return get_data_recording(clips,dtype)\n",
        "    #if grouping == \"aquisition mode\":\n",
        "    #    return get_data_aquisition(clips,dtype)\n",
        "\n",
        "    # If input is invalid, return nothing\n",
        "    print(\"Invalid input to get_data(type). Type can be a string with one of the following values:\")\n",
        "    print(\"patient\")\n",
        "    print(\"chest location\")\n",
        "    print(\"recording equipment\")\n",
        "    print(\"aquisition mode\")\n",
        "    return None\n",
        "\n",
        "# This method splits the data into 4 classes: [\"Normal\",\"Wheeze\",\"Crackle\",\"Both\"]\n",
        "def get_data_default(clips,dtype):\n",
        "    \n",
        "    # Initialize output arrays\n",
        "    data = [[],[],[],[]]\n",
        "    \n",
        "    # Loop through each clip and group the clips by wheeze/crackle detection\n",
        "    for clip in tqdm(clips,\"Grouping data by default\"):\n",
        "        # Get boolean values\n",
        "        c = clip.crackle\n",
        "        w = clip.wheeze\n",
        "        \n",
        "        # Append clip to corresponding list\n",
        "        i = get_index(c,w)\n",
        "        if dtype == \"audio\":\n",
        "            data[i].append(clip.audio)\n",
        "        elif dtype == \"clip\":\n",
        "            data[i].append(clip)\n",
        "        else:\n",
        "            print(\"Found improper dtype:\",dtype)\n",
        "            print(\"Appropriate values for dtype are:\",[\"audio\",\"clip\"])\n",
        "            \n",
        "    # Return the grouped data\n",
        "    return data\n",
        "\n",
        "# This method splits the data into 4 classes, grouped by recording equipment\n",
        "def get_data_recording(clips,dtype):\n",
        "    \n",
        "    # Initialize output arrays\n",
        "    # Each separate list represents clips recorded with the same recording equipment\n",
        "    # Column 0: normal\n",
        "    # Column 1: crackle\n",
        "    # Column 2: wheeze\n",
        "    # Column 3: both\n",
        "    akgc417l = [[],[],[],[]]\n",
        "    littc2se = [[],[],[],[]]\n",
        "    litt3200 = [[],[],[],[]]\n",
        "    meditron = [[],[],[],[]]\n",
        "    \n",
        "    # Loop through each clip and group them\n",
        "    for clip in tqdm(clips,\"Grouping data by recording equipment\"):\n",
        "        \n",
        "        # Get information from clip\n",
        "        c = clip.crackle\n",
        "        w = clip.wheeze\n",
        "        r = clip.rec_equipment\n",
        "        \n",
        "        # Assign index based on booolean wheeze/crackle information\n",
        "        i = get_index(c,w)\n",
        "        \n",
        "        # Append clip to corresponding list based on dtype\n",
        "        if dtype == \"audio\":\n",
        "            if r == \"AKGC417L\":\n",
        "                akgc417l[i].append(clip.audio)\n",
        "            elif r == \"LittC2SE\":\n",
        "                littc2se[i].append(clip.audio)\n",
        "            elif r == \"Litt3200\":\n",
        "                litt3200[i].append(clip.audio)\n",
        "            elif r == \"Meditron\":\n",
        "                meditron[i].append(clip.audio)\n",
        "            else:\n",
        "                print(\"Found improper recording equipment:\",r)\n",
        "        elif dtype == \"clip\":\n",
        "            if r == \"AKGC417L\":\n",
        "                akgc417l[i].append(clip)\n",
        "            elif r == \"LittC2SE\":\n",
        "                littc2se[i].append(clip)\n",
        "            elif r == \"Litt3200\":\n",
        "                litt3200[i].append(clip)\n",
        "            elif r == \"Meditron\":\n",
        "                meditron[i].append(clip)\n",
        "            else:\n",
        "                print(\"Found improper recording equipment:\",r)\n",
        "        else:\n",
        "            print(\"Found improper dtype:\",dtype, \"in\", clip.file_name)\n",
        "            print(\"Appropriate values for dtype are:\",[\"audio\",\"clip\"])\n",
        "    \n",
        "    return akgc417l, littc2se, litt3200, meditron\n",
        "\n",
        "def split_data(classes,train=0,test=0,valid=0):\n",
        "    # Check if the splits are correct\n",
        "    if test + valid + train != 1:\n",
        "        print(\"Splits don't add up to 100%\")\n",
        "        return None\n",
        "    \n",
        "    # Assign array lengths for test, valid, and train sets\n",
        "    splits = np.zeros((3,len(classes)),dtype=int)\n",
        "    i = 0\n",
        "    for c in classes:\n",
        "        total = len(c)\n",
        "        splits[0,i] = int(train * total)\n",
        "        splits[1,i] = int(test * total) + splits[0,i]\n",
        "        splits[2,i] = total\n",
        "        i += 1\n",
        "    \n",
        "    # Split the data set\n",
        "    train_split = []\n",
        "    test_split = []\n",
        "    valid_split = []\n",
        "    for n in range(len(classes)):\n",
        "        train_split.append(classes[n][0:splits[0,n]])\n",
        "        test_split.append(classes[n][splits[0,n]:splits[1,n]])\n",
        "        valid_split.append(classes[n][splits[1,n]:splits[2,n]])\n",
        "\n",
        "    return train_split, test_split, valid_split\n",
        "\n",
        "def crop_clips(clips,seconds,sr):\n",
        "    n_samples = int(seconds*sr)\n",
        "    for clip in tqdm(clips,\"Cropping clips\"):\n",
        "        audio = clip.sound_data\n",
        "        if len(audio) < n_samples:\n",
        "            clip.cropped_sound = np.pad(audio,(0,n_samples - len(audio)))\n",
        "        elif len(audio) > n_samples:\n",
        "            clip.cropped_sound = audio[:n_samples]\n",
        "        else:\n",
        "            clip.cropped_sound = audio\n",
        "    \n",
        "    return clips\n",
        "    \n",
        "def filter_clips(clips,lower,upper,sr):\n",
        "    n_lower = lower * sr\n",
        "    n_upper = upper * sr\n",
        "    output = []\n",
        "    for clip in tqdm(clips,\"Filtering clips\"):\n",
        "        l = len(clip.sound_data)\n",
        "        if l >= n_lower and l <= n_upper:\n",
        "            output.append(clip)\n",
        "    \n",
        "    return crop_clips(output, lower)\n",
        "        \n",
        "def get_index(c,w):\n",
        "    if c and w:\n",
        "        return 3\n",
        "    elif not c and not w:\n",
        "        return 0\n",
        "    elif c:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZoe8qgPPOct"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}